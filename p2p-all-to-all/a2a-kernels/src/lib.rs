#[cxx::bridge(namespace = "a2a_kernels")]
#[allow(clippy::missing_safety_doc)]
#[allow(clippy::too_many_arguments)]
mod ffi {
    unsafe extern "C++" {
        include!("a2a/a2a_kernels.h");

        #[namespace = "torch_lib"]
        type ScalarType = torch_lib::ScalarType;

        unsafe fn a2a_dispatch_send(
            num_blocks: usize,
            hidden_dim: usize,
            hidden_dim_scale: usize,
            num_experts: usize,
            num_experts_per_token: usize,
            max_private_tokens: usize,
            rank: usize,
            dp_size: usize,
            node_size: usize,
            world_size: usize,
            num_tokens: usize,
            bound_m_ptr: *const i32,
            x_ptr: *const u8,
            x_elemsize: usize,
            x_stride: usize,
            x_scale_ptr: *const u8,
            x_scale_elemsize: usize,
            x_scale_stride_elem: usize,
            x_scale_stride_token: usize,
            indices: *const i32,
            indices_stride: usize,
            weights: *const f32,
            weights_stride: usize,
            token_offset: *mut u32,
            num_routed: *mut u32,
            expert_offsets: *mut u32,
            dispatch_route_done: *mut u8,
            dispatch_send_done: *mut u8,
            tx_ready: *mut u8,
            send_buffer: *mut u8,
            grid_counter: *mut u32,
            sync_counter: *mut u32,
            sync_ptrs: *mut *mut u32,
            recv_ptrs: *mut *mut u8,
            stream: u64,
        ) -> i32;

        unsafe fn a2a_dispatch_recv(
            num_blocks: usize,
            hidden_dim: usize,
            hidden_dim_scale: usize,
            x_elemsize: usize,
            x_scale_elemsize: usize,
            num_experts: usize,
            rank: usize,
            node_size: usize,
            world_size: usize,
            out_num_tokens_ptr: *mut i32,
            out_x_ptr: *mut u8,
            out_x_stride: usize,
            out_x_scale_ptr: *mut u8,
            out_x_scale_stride_elem: usize,
            out_x_scale_stride_token: usize,
            tokens_per_expert: *mut u32,
            send_buffer: *mut u8,
            recv_buffer: *mut u8,
            source_rank: *mut u32,
            source_offset: *mut u32,
            padded_index: *mut u32,
            num_routed: *mut u32,
            num_recv_tokens_ptr: *mut u32,
            num_recv_tokens_flag: *mut u8,
            dispatch_recv_flag: *mut u8,
            dispatch_recv_done: *mut u8,
            grid_counter: *mut u32,
            sync_counter: *mut u32,
            sync_ptrs: *mut *mut u32,
            send_ptrs: *mut *mut u8,
            stream: u64,
        ) -> i32;

        unsafe fn a2a_combine_send(
            num_blocks: usize,
            hidden_dim: usize,
            x_elemsize: usize,
            rank: usize,
            node_size: usize,
            dp_size: usize,
            expert_x_ptr: *const u8,
            expert_x_stride: usize,
            tx_ready: *mut u8,
            send_buffer: *mut u8,
            recv_buffer: *mut u8,
            source_rank: *mut u32,
            combine_send_offset: *mut u32,
            padded_index: *mut u32,
            num_recv_tokens_ptr: *mut u32,
            combine_send_done: *mut u8,
            token_counter: *mut u32,
            sync_counter: *mut u32,
            sync_ptrs: *mut *mut u32,
            recv_ptrs: *mut *mut u8,
            stream: u64,
        ) -> i32;

        unsafe fn a2a_combine_recv(
            num_blocks: usize,
            hidden_dim: usize,
            x_elemsize: usize,
            in_dtype: ScalarType,
            out_dtype: ScalarType,
            num_experts: usize,
            num_experts_per_token: usize,
            rank: usize,
            node_size: usize,
            world_size: usize,
            num_tokens: usize,
            bound_m_ptr: *const i32,
            indices_ptr: *const i32,
            indices_stride: usize,
            weights_ptr: *const f32,
            weights_stride: usize,
            out_tokens_ptr: *mut u8,
            out_tokens_stride: usize,
            accumulate: bool,
            recv_buffer: *mut u8,
            token_offset: *mut u32,
            expert_offsets: *mut u32,
            combine_recv_flag: *mut u8,
            combine_recv_done: *mut u8,
            sync_counter: *mut u32,
            sync_ptrs: *mut *mut u32,
            stream: u64,
        ) -> i32;
    }
}

pub use ffi::{
    a2a_combine_recv, a2a_combine_send, a2a_dispatch_recv, a2a_dispatch_send,
};
